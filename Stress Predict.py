# -*- coding: utf-8 -*-
"""Separate_data_sets_23nd_ (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FcQbCz8xZ9Xld8WeXh-xW0gzzFOpv1kK
"""

import os
import pandas as pd
import numpy as np
import multiprocessing
import matplotlib.pyplot as plt
import seaborn as sns
import joblib


from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.model_selection import RandomizedSearchCV
from imblearn.over_sampling import SMOTE

#models
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import GradientBoostingClassifier

from sklearn.metrics import make_scorer
from sklearn.metrics import f1_score as f1
from sklearn.metrics import confusion_matrix, classification_report


import warnings
# ignore all warnings
warnings.filterwarnings("ignore")

final_columns = {
    'ACC': ['id', 'X', 'Y', 'Z', 'datetime'],
    'BVP': ['id', 'BVP', 'datetime'],
    'EDA': ['id', 'EDA', 'datetime'],
    'HR': ['id', 'HR', 'datetime'],
    'TEMP': ['id', 'TEMP', 'datetime'],
}

names = {                                                                                                                                                                                                                                                              
    'ACC': ['X', 'Y', 'Z'],
    'BVP': ['BVP'],
    'EDA': ['EDA'],
    'HR': ['HR'],
    'TEMP': ['TEMP'],
    'tags':['tags']
}

desired_signals = ['ACC', 'BVP','EDA', 'HR', 'TEMP']

def process_df(df, file):
    start_timestamp = df.iloc[0, 0]
    sample_rate = df.iloc[1, 0]
    new_df = pd.DataFrame(df.iloc[2:].values, columns=df.columns)
    new_df['id'] = file
    new_df['datetime'] = [(start_timestamp + i / sample_rate) for i in range(len(new_df))]

    return new_df

data = {}
for file in range(2,36):       
    
    if file > 9:
       data_path_acc = "https://raw.githubusercontent.com/italha-d/Stress-Predict-Dataset/main/Raw_data/S" + str(file) + "/" + "ACC.csv"
       data_path_bvp = "https://raw.githubusercontent.com/italha-d/Stress-Predict-Dataset/main/Raw_data/S" + str(file) + "/" + "BVP.csv"
       data_path_eda = "https://raw.githubusercontent.com/italha-d/Stress-Predict-Dataset/main/Raw_data/S" + str(file) + "/" + "EDA.csv"
       data_path_hr = "https://raw.githubusercontent.com/italha-d/Stress-Predict-Dataset/main/Raw_data/S" + str(file) + "/" + "HR.csv"
       data_path_temp = "https://raw.githubusercontent.com/italha-d/Stress-Predict-Dataset/main/Raw_data/S" + str(file) + "/" + "TEMP.csv"

    else:
       data_path_acc = "https://raw.githubusercontent.com/italha-d/Stress-Predict-Dataset/main/Raw_data/S0" + str(file) + "/" + "ACC.csv"
       data_path_bvp = "https://raw.githubusercontent.com/italha-d/Stress-Predict-Dataset/main/Raw_data/S0" + str(file) + "/" + "BVP.csv"
       data_path_eda = "https://raw.githubusercontent.com/italha-d/Stress-Predict-Dataset/main/Raw_data/S0" + str(file) + "/" + "EDA.csv"
       data_path_hr = "https://raw.githubusercontent.com/italha-d/Stress-Predict-Dataset/main/Raw_data/S0" + str(file) + "/" + "HR.csv"
       data_path_temp = "https://raw.githubusercontent.com/italha-d/Stress-Predict-Dataset/main/Raw_data/S0" + str(file) + "/" + "TEMP.csv"

    acc = pd.read_csv(data_path_acc, names=names['ACC'], header=None)
    bvp = pd.read_csv(data_path_bvp, names=names['BVP'], header=None)
    eda = pd.read_csv(data_path_eda, names=names['EDA'], header=None)
    hr = pd.read_csv(data_path_hr, names=names['HR'], header=None)
    temp = pd.read_csv(data_path_temp, names=names['TEMP'], header=None)


    acc =  process_df(acc, file)
    bvp = process_df(bvp, file)
    eda = process_df(eda, file)
    hr = process_df(hr, file)
    temp = process_df(temp, file)

    columns = ['X', 'Y', 'Z', 'BVP', 'EDA', 'HR', 'TEMP', 'id', 'datetime']
    
    df = pd.DataFrame(columns=columns)

    bvp_id = bvp[bvp['id'] == file]
    acc_id = acc[acc['id'] == file].drop(['id'], axis=1)
    eda_id = eda[eda['id'] == file].drop(['id'], axis=1)
    hr_id = hr[hr['id'] == file].drop(['id'], axis=1)
    temp_id = temp[temp['id'] == file].drop(['id'], axis=1)

    
    df = pd.merge(acc_id, bvp_id, on='datetime'  , how='outer')
    df = pd.merge(df, eda_id, on='datetime'  , how='outer')
    df = pd.merge(df, hr_id, on='datetime'  , how='outer')
    df = pd.merge(df, temp_id, on='datetime'  , how='outer')


    df.fillna(method='ffill', inplace=True)
    df.fillna(method='bfill', inplace=True)

    df["datetime"] = df["datetime"].astype(int)

    data[f"df{file}"] = df

for i in range(2, 36):
    globals()[f"df{i}"] = data[f"df{i}"]

df2

tag_data = {}
for i in range(2, 36):
    data_path = "https://raw.githubusercontent.com/italha-d/Stress-Predict-Dataset/main/Raw_data/"
    if i > 9:          
        data_path = data_path + "S" + str(i) + "/" + "tags" + "_S" + str(i) + ".csv"  
    else:   
        data_path = data_path + "S" + ("0" + str(i)) +"/" + "tags" + "_S" + ("0" + str(i)) +".csv"
        
    df_tags = pd.read_csv(data_path, names=names['tags'], header=None)
    df_tags['tags'] = round(df_tags['tags']).astype(int)
    tag_data[i] = df_tags['tags'].tolist()

for i in range(2, 36):
    globals()[f"tag{i}"] = tag_data[i]

tag30

######## label Match ##################

for key, df in data.items():
    col = ['X', 'Y', 'Z', 'datetime', 'id', 'BVP', 'EDA', 'HR', 'TEMP', 'outcome']
    num_rows = len(df)
    outcome = [0] * num_rows
    df = pd.DataFrame(df, columns=col)
    df['outcome'] = outcome

    # function to update the outcome based on tag data
    def update_outcome(group):
        tags = tag_data[group['id'].iloc[0]]
        tag_idx = 0
        outcome = 0

        for idx, row in group.iterrows():
            if row['datetime'] == tags[tag_idx]:
                outcome = (outcome + 1) % 2
                tag_idx += 1
                if tag_idx >= len(tags):
                    break
            group.at[idx, 'outcome'] = outcome

        return group

    df = df.groupby('id').apply(update_outcome)

    df = df.dropna()

    # assign cleaned data frame back to original variable
    data[key] = df

for i in range(2, 36):
    globals()[f"df{i}"] = data[f"df{i}"]

df2

######################## Start Preprocessing for all data sets #############################

# Remove id and datetime variable 
for df_name in data:
    data[df_name] = data[df_name].drop(["id", "datetime"], axis=1)

for i in range(2, 36):
    globals()[f"df{i}"] = data[f"df{i}"]

df3

#Create new variables with signal data

for key, df in data.items():
    # Take modulus of required columns
    df[['X', 'Y', 'Z']] = df[['X', 'Y', 'Z']].apply(lambda x: x % 10)
    # Update dictionary with modified dataframe
    data[key] = df

# Define the subplots
fig, axs = plt.subplots(nrows=7, ncols=5, figsize=(15,10))

# Flatten the axs array for easier iteration
axs = axs.flatten()

# Iterate over the dataframes and plot the charts
for i, df_name in enumerate(data):
    # Select the dataframe
    df = data[df_name]
    
    # Count the values of the outcome column and plot the bar chart
    ax = axs[i]
    df["outcome"].value_counts().plot(kind="bar", color=["salmon","deeppink"], ax=ax)
    ax.set_xticks(np.arange(2))
    ax.set_xticklabels(('No Stressed', 'Stressed'), rotation=0)
    ax.set_title(df_name)

# Remove any extra subplots
for ax in axs[len(data):]:
    ax.remove()

# Display the plot
plt.tight_layout()
plt.show()

to_remove = ['df18','df30']

# Create a new dictionary by iterating over the original dictionary and excluding the keys in to_remove list
data = {k:v for k,v in data.items() if k not in to_remove}

#SMOTE balancing
# Define the SMOTE object
sm = SMOTE(random_state=42)

# Loop over each dataframe and balance the classes using SMOTE
for i, df_name in enumerate(data):
    # Select the dataframe
    df = data[df_name]
    
    # Separate features and target variable
    X = df.drop("outcome", axis=1)
    y = df["outcome"]
    
    # Apply SMOTE
    X_resampled, y_resampled = sm.fit_resample(X, y)
    
    # Update the original dataframe with the balanced data
    df_resampled = X_resampled.copy()
    df_resampled["outcome"] = y_resampled
    data[df_name] = df_resampled

import matplotlib.pyplot as plt
import seaborn as sns

# Define the subplots
fig, axs = plt.subplots(nrows=7, ncols=5, figsize=(20, 25))

# Flatten the axs array for easier iteration
axs = axs.flatten()

# Iterate over the dataframes and plot the heatmaps
for i, df_name in enumerate(data):
    # Select the dataframe
    df = data[df_name]
    
    # Compute the correlation matrix and plot the heatmap
    ax = axs[i]
    corr_matrix = df.corr()
    sns.heatmap(corr_matrix,
                annot=True,
                linewidth=0.5,
                annot_kws={"fontsize":8},
                fmt=".2f",
                cmap="YlGnBu",
                ax=ax)
    ax.set_title(df_name)
    ax.set_xlabel('')
    ax.set_ylabel('')
    
    # Hide any extra subplots
    if i >= len(data) - 1:
        ax.set_visible(False)

# Display the plot
plt.tight_layout()
plt.show()

# Remove BVP variable 
for df_name in data:
    data[df_name] = data[df_name].drop("BVP", axis=1)

for i in range(2, 36):
    if i in [18, 30]:
        continue
    globals()[f"df{i}"] = data[f"df{i}"]

###################################### check furter for separate data sets (df2, df17, df28) #############################################################

_ = df2.hist(bins=50, figsize=(12,6))

_ = df17.hist(bins=50, figsize=(12,6))

_ = df28.hist(bins=50, figsize=(12,6))

variables = ['EDA', 'HR', 'TEMP']

fig, axs = plt.subplots(len(variables), 3, figsize=(15, len(variables)*3))

for i, var in enumerate(variables):
    _ = df2[var].hist(bins=50, ax=axs[i, 0])
    _ = df17[var].hist(bins=50, ax=axs[i, 1])
    _ = df28[var].hist(bins=50, ax=axs[i, 2])

    axs[i, 0].set_title('df2')
    axs[i, 1].set_title('df17')
    axs[i, 2].set_title('df28')
    axs[i, 0].set_ylabel(var)

fig.suptitle('Distributions of Variables')

plt.show()

variables = ['EDA', 'HR', 'TEMP']

fig, axs = plt.subplots(len(variables), 3, figsize=(15, len(variables)*3))

for i, var in enumerate(variables):
    _ = df2[var][df2.outcome == 1].hist(bins=50, ax=axs[i, 0])
    _ = df17[var][df17.outcome == 1].hist(bins=50, ax=axs[i, 1])
    _ = df28[var][df28.outcome == 1].hist(bins=50, ax=axs[i, 2])

    axs[i, 0].set_title('df2')
    axs[i, 1].set_title('df17')
    axs[i, 2].set_title('df28')
    axs[i, 0].set_ylabel(var)

fig.suptitle('Distributions of Variables for Outcome = 1')

plt.show()

variables = ['EDA', 'HR', 'TEMP']

fig, axs = plt.subplots(len(variables), 3, figsize=(15, len(variables)*3))

for i, var in enumerate(variables):
    _ = df2[var][df2.outcome == 0].hist(bins=50, ax=axs[i, 0])
    _ = df17[var][df17.outcome == 0].hist(bins=50, ax=axs[i, 1])
    _ = df28[var][df28.outcome == 0].hist(bins=50, ax=axs[i, 2])

    axs[i, 0].set_title('df2')
    axs[i, 1].set_title('df17')
    axs[i, 2].set_title('df28')
    axs[i, 0].set_ylabel(var)

fig.suptitle('Distributions of Variables for Outcome = 0')

plt.show()

#################################### Modeling ####################################################################

"""# Modeling"""

# Create a list of data frames
dfs = [df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12, df13, df14, df15, df16, df17, df19, df20, df21, df22, df23, df24, df25, df26, df27, df28, df29, df31, df32, df33, df34, df35]

X_train_data = []
X_test_data = []
y_train_data = []
y_test_data = []

# Train a logistic regression model for each data frame
for i, df in enumerate(dfs):
    # Split the data
    X = df.drop("outcome", axis=1)
    y = df["outcome"]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
    
    # Save the data
    X_train_data.append(X_train)
    X_test_data.append(X_test)
    y_train_data.append(y_train)
    y_test_data.append(y_test)

# Train a logistic regression model for each data frame

scores_lr = []

for i in range(len(X_train_data)):
    # Train the model on this set of data
    log_reg = LogisticRegression(random_state=0)
    log_reg.fit(X_train_data[i], y_train_data[i])

    # Test the model on this set of data
    score = log_reg.score(X_test_data[i], y_test_data[i])
    scores_lr.append(score)
    print(f"Model LR {i+1} score: {score}")

# Calculate the average score
average_score_LR = np.mean(scores_lr)
print(f"Average score LR: {average_score_LR}")

# Train a KNN model for each data frame

scores_knn = []

for i, df in enumerate(dfs):
    
    # Train the model
    knn = KNeighborsClassifier()
    knn.fit(X_train_data[i], y_train_data[i])
    
    # Test the model on this set of data
    score = knn.score(X_test_data[i], y_test_data[i])
    scores_knn.append(score)
    print(f"Model KNN {i+1} score: {score}")

# Calculate the average score
average_score_KNN = np.mean(scores_knn)
print(f"Average score KNN: {average_score_KNN}")

# Train a Random Forest model for each data frame

scores_rf = []

for i, df in enumerate(dfs):
    
    # Train the model
    rf= RandomForestClassifier()
    rf.fit(X_train_data[i], y_train_data[i])
    
    # Test the model on this set of data
    score = rf.score(X_test_data[i], y_test_data[i])
    scores_rf.append(score)
    print(f"Model RF {i+1} score: {score}")

# Calculate the average score
average_score_RF = np.mean(scores_rf)
print(f"Average score RF: {average_score_RF}")

# Train a  Gradient Boost model for each data frame

scores_gb = []

for i, df in enumerate(dfs):  
    
    # Train the model
    gb = GradientBoostingClassifier(random_state=0)
    gb.fit(X_train_data[i], y_train_data[i])
    
    # Test the model on this set of data
    score = gb.score(X_test_data[i], y_test_data[i])
    scores_gb.append(score)
    print(f"Model GB {i+1} score: {score}")

# Calculate the average score
average_score_GB = np.mean(scores_gb)
print(f"Average score GB: {average_score_GB}")

model_compare = pd.DataFrame({"Logistic Regression":average_score_LR,
                            "KNN":average_score_KNN,
                            "Random Forest":average_score_RF,
                           "Gradient Boost":average_score_GB
                            },index=["accuracy"])

model_compare.T.plot(kind='line', figsize=(6, 3))

"""# Hyperparameter tuning using RandomizedSearchcv

# Best Model is Random Forest with 99.92% accuracy:
"""

#saving model 

joblib.dump(rf, 'C:\\Users\\USER\\Desktop\\Decision making\\rf.pkl')

y_preds_data = []

for i, df in enumerate(dfs):
    y_preds = rf.predict(X_test_data[i])
    y_preds_data.append(y_preds)

y_test_data_array = []

# loop through the dataframes and convert each one to a numpy array
for df in y_test_data:
    arr = df.values
    y_test_data_array.append(arr)

y_test_data_array

# loop over the dataframes and corresponding predictions
for i, (X_test, y_test, y_preds) in enumerate(zip(X_test_data, y_test_data, y_preds_data)):
    # compute the confusion matrix
    cm = confusion_matrix(y_test, y_preds)
    print(f"Confusion matrix for model {i+1}:")
    print(cm)

sns.set(font_scale=2)

for i in range(len(X_test_data)):
    # Predict on test data
    y_preds = rf.predict(X_test_data[i])

    # Calculate confusion matrix
    cm = confusion_matrix(y_test_data[i], y_preds)

    # Plot confusion matrix
    plt.figure(figsize=(8,6))
    sns.heatmap(cm, annot=True, cbar=False, fmt='g')
    plt.xlabel("Predicted label")
    plt.ylabel("True label")
    plt.title(f"Confusion matrix for data frame {i+1}")
    plt.show()

fig, axs = plt.subplots(nrows=7, ncols=5, figsize=(20, 25))

for i, ax in enumerate(axs.flatten()):
    # Plot the i-th dataset
    sns.heatmap(confusion_matrix(y_preds_data[i], y_test_data_array[i]), annot=True, cbar=False, fmt='g', ax=ax)
    ax.set_xlabel("True label")
    ax.set_ylabel("Predicted label")
    ax.set_title(f"Dataset {i+1}")
    
plt.tight_layout()

fn_rates = []
for cm in confusion_matrix_data:
    tn, fp, fn, tp = cm.ravel()
    fn_rate = round(fn/(fn+tp+tn+fp)*100, 2)
    fn_rates.append(fn_rate)

avg_fn_rate = np.mean(fn_rates)
print("Average FN Rate:", avg_fn_rate)

fn_rates

fig, ax = plt.subplots()
ax.hist(fn_rates, bins=10, alpha=0.5, edgecolor='black')
ax.set_xlabel('Rate')
ax.set_ylabel('Frequency')
ax.set_title('False Negatives')
plt.show()

# Print the classification report for each data frame
for i, df in enumerate(dfs):
    # Load the saved data
    X_train = X_train_data[i]
    X_test = X_test_data[i]
    y_train = y_train_data[i]
    y_test = y_test_data[i]
    y_preds = y_preds_data[i]

    # Print the classification report
    print(f"Classification report for Model {i+1}")
    print(classification_report(y_test, y_preds))
    print("\n")

# Evaluate the bestmodel # cross validation

rf_scores = []

for i, _ in enumerate(X_train_data):

    rf_scores = cross_val_score(rf, X_train_data[i], y_train_data[i], cv=10, scoring=make_scorer(f1))
    scores_rf.append(rf_scores)

    rf_scores.mean()

    rf_scores

rf_scores

# Cross-validated accuracy
cv_acc = cross_val_score(rf,
                         X_train_data[0], y_train_data[0],
                         cv=5,
                         scoring="accuracy")
cv_acc = np.mean(cv_acc)
cv_acc



# Cross-validated precision
cv_precision = cross_val_score(rf,
                         X_train_data[0], y_train_data[0],
                         cv=5,
                         scoring="precision")
cv_precision=np.mean(cv_precision)
cv_precision

# Cross-validated recall
cv_recall = cross_val_score(rf,
                         X_train_data[0], y_train_data[0],
                         cv=5,
                         scoring="recall")
cv_recall = np.mean(cv_recall)
cv_recall

# Cross-validated f1-score
cv_f1 = cross_val_score(rf,
                        X_train_data[0], y_train_data[0],
                         cv=5,
                         scoring="f1")
cv_f1 = np.mean(cv_f1)
cv_f1

# Visualize cross-validated metrics
cv_metrics = pd.DataFrame({"Accuracy": cv_acc,
                           "Precision": cv_precision,
                           "Recall": cv_recall,
                           "F1": cv_f1},
                          index=[0])

cv_metrics.T.plot.line(title="Cross-validated classification metrics",legend=False)

# Fit an instance of Random Forest
clf = RandomForestClassifier(n_estimators=100, max_depth=10)

clf.fit(X_train_data[0], y_train_data[0])

# extract feature importances
importances = clf.feature_importances_

# create a dictionary of feature names and their importances
feature_dict = dict(zip(X_train_data[0].columns, importances))

# sort the features by importance in descending order
sorted_features = sorted(feature_dict.items(), key=lambda x: x[1], reverse=True)

# extract the top 10 features
top_features = dict(sorted_features[:10])

# plot the top features
plt.barh(range(len(top_features)), list(top_features.values()))
plt.yticks(range(len(top_features)), list(top_features.keys()))
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.title('Top Features')
plt.show()